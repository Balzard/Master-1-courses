{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vector Quantization (1H-1H30)\n",
    "\n",
    "(A) First of all, start by finalizing the given competive learning algorithm, complete the update rule for the centroid and for the learning rate value, $\\alpha$.\n",
    "\n",
    "(B) Afterwards you'll need to implement the following algorithms:\n",
    "1. Frequency sensitive learning (a slight alteration of competitive learning)\n",
    "2. K-means (a batched form of competitive learning)\n",
    "3. **[@Home]** Implement the neural gas algorithm (a winner-take-most alteration of competitive learning)\n",
    "\n",
    "(C) You'll try out 3 different centroid initializations for these algorithms:\n",
    "1. A (given) *random* init\n",
    "2. A *random selection* of points\n",
    "3. KMeans++\n",
    "\n",
    "Test those 3 initializations with the 4 given datasets and answer the following questions:\n",
    "* For each algorithm, which initialization works best and why?\n",
    "* Should you apply a larger/lower learning rate to K-means? Why?\n",
    "\n",
    "Answers:\n",
    "* K-means++ for K-means and sampling for the others because of forgotten centroids (centroids that have no assigned points). FSL does partly solve this last problem\n",
    "* K-means uses a batch update and thus its learning rate can be bumped up, otherwise it will converge too early due to the annealing of $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Imports\n",
    "from show_functions import show_quantization\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    use_seaborn = True\n",
    "    sns.set()\n",
    "except:\n",
    "    use_seaborn = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.0 Competitive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from show_functions import show_quantization\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# -- Competitive Learning\n",
    "def comp_learning(X: np.ndarray, Y: np.ndarray, n_epochs: int = 100, alpha: float = 0.1, beta: float = 0.99, min_epsilon: float = 1e-3):\n",
    "    \"\"\" Computes and returns the centroids updated via the competitive learning algorithm\n",
    "        \n",
    "        Args:\n",
    "            X: a matrix of shape PxD representing the data-points\n",
    "            Y: a matrix of shape QxD representing the centroids' initilization\n",
    "            n_epochs: the maximum number of epochs before stopping the algorithm\n",
    "            alpha: the learning rate\n",
    "            beta: the learning rate annealing rate\n",
    "            min_epsilon: the minimal stopping criterion\n",
    "        \n",
    "        Returns:\n",
    "            Y: a matrix of shape QxD containing the new centroid\n",
    "            epoch: the number of epochs before returning (is always <= n_epochs)\n",
    "    \"\"\"\n",
    "    assert len(X.shape)==2 and len(Y.shape)==2, f\"Expected X and Y to both be 2D matrices but instead got {X.shape} and {Y.shape}\"\n",
    "    for epoch in range(n_epochs):\n",
    "        prev_Y = Y.copy()\n",
    "        \n",
    "        # Shuffle Data\n",
    "        np.random.shuffle(X)\n",
    "        \n",
    "        # Use up every data point\n",
    "        for xp in X:\n",
    "            ## TODO\n",
    "            Z = xp - Y #python will scale xp to be dim of Y\n",
    "            Z2 = np.linalg.norm(xp - Y, axis = -1)\n",
    "            index = np.argmin(Z2)\n",
    "            yq = Y[index]\n",
    "            Y[index] = yq + alpha*(xp-yq)\n",
    "                \n",
    "        # Update Learning Rate\n",
    "        alpha = (alpha*beta)/(alpha+beta)\n",
    "        \n",
    "        # 'Intelligent' stopping criterion\n",
    "        if np.mean(np.abs(prev_Y-Y)) < min_epsilon: ## TODO\n",
    "            break\n",
    "\n",
    "    return Y, epoch+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1 Frequency Sensitive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Frequency Sensitive Learning\n",
    "def fsl(X, Y, n_epochs=100, alpha=0.1, beta=0.99, min_epsilon=1e-3):\n",
    "    \"\"\" Computes and returns the centroids updated via the Frequency Sensitive Learning algorithm\n",
    "    \"\"\"\n",
    "    assert len(X.shape)==2 and len(Y.shape)==2, f\"Expected X and Y to both be 2D matrices but instead got {X.shape} and {Y.shape}\"\n",
    "    u = shape(Y).1 #or len(Y) or Y.shape[0]\n",
    "    \n",
    "    Z = xp - Y\n",
    "    Z2 = np.linalg.norm()\n",
    "    yq = yq + alpha*(xp-yq)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- K-means\n",
    "def kmeans(X, Y, n_epochs=100, min_epsilon=1e-3, use_broadcasting=True):\n",
    "    \"\"\" Computes and returns the centroids updated via the K-means algorithm\n",
    "    \n",
    "        Args:\n",
    "            use_broadcasting: if True will use more memory for the K-means algorithm\n",
    "    \"\"\"\n",
    "    assert len(X.shape)==2 and len(Y.shape)==2, f\"Expected X and Y to both be 2D matrices but instead got {X.shape} and {Y.shape}\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3 Neural Gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Neural Gas\n",
    "def neural_gas(X, Y, lambda0=0.5, n_epochs=100, alpha=0.1, beta=0.99, min_epsilon=1e-3):\n",
    "    \"\"\" Computes and returns the centroids updated via the Neural Gas algorithm\n",
    "    \n",
    "        Args:\n",
    "            lambda0: The higher lambda0, the more influence far away points will have\n",
    "    \"\"\"\n",
    "    assert len(X.shape)==2 and len(Y.shape)==2, f\"Expected X and Y to both be 2D matrices but instead got {X.shape} and {Y.shape}\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Different Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -- Kmeans++ init\n",
    "def kmeans_pp(X: np.ndarray, Q: int):\n",
    "    \"\"\" Computes Q centroids for X following the kmeans++ init. algorithm\n",
    "        \n",
    "        Args:\n",
    "            X: a matrix of shape PxD representing the data-points\n",
    "            Q: the number of centroids\n",
    "        \n",
    "        Returns:\n",
    "            Y: a matrix of shape QxD containing the initialized centers\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def get_inits(X, Q, i):\n",
    "    inits = {}\n",
    "    mini = np.min(X, axis=0)\n",
    "    maxi = np.max(X, axis=0)\n",
    "    if i == 1:\n",
    "        inits[\"Crappy\"] = np.array([\n",
    "            [0,3],[1,0],[1,1.5]\n",
    "        ])\n",
    "\n",
    "    ## TODO\n",
    "    return inits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. VQ-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data1/dataset_1.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data1/dataset_1.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab574606ab8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data1/dataset_{i}.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \"\"\"\n\u001b[1;32m    221\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data1/dataset_1.mat'"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i in range(1,5):\n",
    "    df = scipy.io.loadmat(f\"data1/dataset_{i}.mat\")\n",
    "    data[i-1] = df['X']\n",
    "\n",
    "# Uncomment more functions once you've implemented them\n",
    "fxs = {\"Init\": (lambda x,y,*args,**kwargs: (y,0)), \"Comp. Learn.\": comp_learning}#, \"FSL\": fsl, \"K-means\": kmeans}#, \"Neural Gas\": neural_gas}\n",
    "Q = 3\n",
    "i = 1\n",
    "X = data[i]\n",
    "X = np.array(X)\n",
    "all_Y_inits = get_inits(X, Q, i)\n",
    "\n",
    "fig = plt.figure(figsize=((len(all_Y_inits)+1)*5, 1+5*len(fxs)))\n",
    "idx = 1\n",
    "for cl_type, fx in fxs.items():\n",
    "    for init_idx, (init_type, Y_init) in enumerate(all_Y_inits.items()):\n",
    "        ax = fig.add_subplot(len(fxs), len(all_Y_inits), idx)\n",
    "        centroids, fit_epochs = fx(X, Y_init.copy(), n_epochs=10)#, min_epsilon=1e-3)\n",
    "        try:\n",
    "            show_quantization(X, centroids, use_seaborn=use_seaborn, ax=ax)\n",
    "        except:\n",
    "            pass\n",
    "        idx += 1\n",
    "        if cl_type==\"Init\":\n",
    "            ax.set_title(f\"{init_type} init.\", fontweight=\"bold\", fontsize=15)\n",
    "        elif init_idx==0:\n",
    "            title = ax.set_title(f\"{cl_type}\", fontweight=\"bold\", fontsize=13, rotation='vertical',\n",
    "                                 x=-0.2, y=0.3)\n",
    "    \n",
    "\n",
    "fig.suptitle(f\"Dataset #{i+1}\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "## Correlation and Univariate regression\n",
    "\n",
    "This part constitutes an introduction to linear regression.\n",
    "* **Load the dataset** and plot each feature in function of the blood sugar levels. If you had to select 1 feature only, which one would you keep? \n",
    "* **Implement the correlation** (numpy.corrcoef) factor to check your answer. What does a negative correlation mean?\n",
    "* **Plot** the resulting linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54b50c75bc07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data2/diabetes.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m t_names = [\"age\", \"sex\", \"bmi\", \"blood_pressure\", \"serum_1\", \n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "df = scipy.io.loadmat(f\"data2/diabetes.mat\")\n",
    "X = df[\"X\"]\n",
    "n_samples, n_feats = X.shape\n",
    "t = df[\"t\"]\n",
    "t_names = [\"age\", \"sex\", \"bmi\", \"blood_pressure\", \"serum_1\", \n",
    "           \"serum_2\", \"serum_3\", \"serum_4\", \"serum_5\", \"serum_6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyLinearRegressor(BaseEstimator):\n",
    "    def __init__(self, add_bias=True):\n",
    "        super().__init__()\n",
    "        self.add_bias = add_bias\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.add_bias:\n",
    "            X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=-1)\n",
    "        if len(y.shape) < 2:\n",
    "            y = np.expand_dims(y, axis=-1) #Q -> Qx1\n",
    "        ## TODO\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "        #return self.w*x + self.bias\n",
    "    \n",
    "    def fit_predict(self, X, y):\n",
    "        return self.fit(X, y).predict(X)\n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
